{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import CnnPolicy\n",
    "\n",
    "from pettingzoo.butterfly import pistonball_v6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the PettingZoo environment(information could be found: https://www.pettingzoo.ml/butterfly/pistonball ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pistonball_v6.parallel_env(\n",
    "    n_pistons=20,\n",
    "    time_penalty=-0.1,\n",
    "    continuous=True,\n",
    "    random_drop=True,\n",
    "    random_rotate=True,\n",
    "    ball_mass=0.75,\n",
    "    ball_friction=0.3,\n",
    "    ball_elasticity=1.5,\n",
    "    max_cycles=125,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjust the environment with SuperSuit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ss.color_reduction_v0(env, mode=\"B\") #remove useless color\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84) #shrink observation\n",
    "env = ss.frame_stack_v1(env, 3) #stack the past few frames together to compute acceleration\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env) #parameter sharing of the policy netword on the environment\n",
    "env = ss.concat_vec_envs_v1(env, 8, num_cpus=4, base_class=\"stable_baselines3\") #set the environment to run multiple versions of itself in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instantiates the PPO learning object, define model \n",
    "(model information could be found: https://medium.com/aureliantactics/ppo-hyperparameters-and-ranges-6fc2d29bccbe ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    CnnPolicy,\n",
    "    env,\n",
    "    verbose=3,\n",
    "    gamma=0.95,\n",
    "    n_steps=256,\n",
    "    ent_coef=0.0905168,\n",
    "    learning_rate=0.00062211,\n",
    "    vf_coef=0.042202,\n",
    "    max_grad_norm=0.9,\n",
    "    gae_lambda=0.99,\n",
    "    n_epochs=5,\n",
    "    clip_range=0.3,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=2000000) #actions taken by an individual agent\n",
    "model.save(\"policy\") #saves the policy network to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reinstantiate the environment and load policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = pistonball_v6.env()\n",
    "env = ss.color_reduction_v0(env, mode=\"B\")\n",
    "env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "model = PPO.load(\"policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the policy to render it on your desktop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for agent in env.agent_iter():\n",
    "    obs, reward, done, info = env.last()\n",
    "    act = model.predict(obs, deterministic=True)[0] if not done else None\n",
    "    env.step(act)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('zoo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88a93e89b8a11d2f445313f46f93cc3120b7248de9ac4e9c249ecb557e7cf9b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
